# -*- coding: utf-8 -*-
"""LSTM最终版.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKNlE7F3To1u_hc6MmHP0A6jYFitSmRq
"""

import os
import re
import time
import numpy as np
import pandas as pd
import pickle as pkl
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
import logging

from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from sklearn.metrics import (accuracy_score, classification_report, recall_score,
                            confusion_matrix, f1_score, roc_auc_score)
from sklearn.metrics import roc_curve, auc
from datetime import datetime
from sklearn.model_selection import train_test_split

# 配置日志和随机种子
def setup_environment():
    np.random.seed(42)
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(42)
    torch.backends.cudnn.deterministic = True

class Config:
    def __init__(self, model_type="LSTM"):  # 添加模型类型参数
        # 设备配置
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_type = model_type  # 新增模型类型标识

        # 数据路径
        self.data_path = 'drive/MyDrive/dataset/data0412.csv'
        self.vocab_path = 'drive/MyDrive/LSTM/dataset/vocab.pkl'
        self.embedding_path = 'drive/MyDrive/LSTM/dataset/embedding_Tencent.npz'

        # 训练参数
        self.batch_size = 128
        self.pad_size = 50
        self.num_epochs = 30
        self.learning_rate = 1e-3
        self.patience = 5
        self.min_lr = 1e-5

        # 模型参数
        self.embed_dim = 200
        self.hidden_size = 128
        self.num_layers = 2
        self.dropout = 0.5
        self.num_classes = 2
        self.num_filters = 128

        # 输出目录（按模型类型区分）
        self.output_dir = f"drive/MyDrive/LSTM/outputs/{model_type}_{datetime.now().strftime('%Y%m%d_%H%M')}"
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(f"{self.output_dir}/figures", exist_ok=True)
config = Config()

class TextDataset(Dataset):
    def __init__(self, comments, labels, vocab, tokenizer, pad_size):
        self.comments = comments
        self.labels = labels
        self.vocab = vocab
        self.tokenizer = tokenizer
        self.pad_size = pad_size

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        comment = str(self.comments[idx])
        label = self.labels[idx]

        # 分词和编码
        tokens = self.tokenizer(comment)
        # 如果字长度小于指定长度，则填充，否则截断
        if len(tokens) < self.pad_size:
            tokens.extend(['<PAD>'] * (self.pad_size - len(tokens)))
        else:
            tokens = tokens[:self.pad_size]

        # 如果在词表vocab中有word这个单词，那么就取出它的id；
        # 如果没有，就去除UNK（未知词）对应的id，其中UNK表示所有的未知词（out of vocab）都对应该id
        ids = [self.vocab.get(token, self.vocab.get('<UNK>')) for token in tokens]

        return torch.LongTensor(ids), torch.LongTensor([label])

class LSTM(nn.Module):
    def __init__(self, embedding_pretrained):
        super().__init__()
        self.embedding = nn.Embedding.from_pretrained(embedding_pretrained, freeze=False)
        self.lstm = nn.LSTM(
            input_size=config.embed_dim,
            hidden_size=config.hidden_size,
            num_layers=config.num_layers,
            batch_first=True,
            dropout=config.dropout if config.num_layers > 1 else 0
        )
        self.fc = nn.Linear(config.hidden_size, config.num_classes)
        self.dropout = nn.Dropout(config.dropout)

    def forward(self, x):
        embeds = self.embedding(x)
        _, (h_n, _) = self.lstm(embeds)

        # 获取最后一层的隐藏状态
        out = self.dropout(h_n[-1])
        return self.fc(out)

# 带Attention的双向LSTM模型
class AttentionLSTM(nn.Module):
    def __init__(self, embedding_pretrained):
        super().__init__()
        self.embedding = nn.Embedding.from_pretrained(embedding_pretrained, freeze=False)
        self.lstm = nn.LSTM(
            input_size=config.embed_dim,
            hidden_size=config.hidden_size,
            num_layers=config.num_layers,
            bidirectional=True,
            batch_first=True,
            dropout=config.dropout if config.num_layers > 1 else 0
        )
        self.attention = nn.Sequential(
            nn.Linear(config.hidden_size * 2, config.hidden_size),
            nn.Tanh(),
            nn.Linear(config.hidden_size, 1, bias=False)
        )
        self.fc = nn.Linear(config.hidden_size * 2, config.num_classes)
        self.dropout = nn.Dropout(config.dropout)

    def forward(self, x):
        embeds = self.embedding(x)
        lstm_out, _ = self.lstm(embeds)

        # Attention机制
        attention_weights = torch.softmax(self.attention(lstm_out).squeeze(-1), dim=1)
        out = torch.sum(attention_weights.unsqueeze(-1) * lstm_out, dim=1)

        out = self.dropout(out)
        return self.fc(out)

class CNN_LSTM(nn.Module):
    def __init__(self, embedding_pretrained):
        super().__init__()
        self.embedding = nn.Embedding.from_pretrained(embedding_pretrained, freeze=False)

        # 添加1D卷积层
        self.conv = nn.Conv1d(
            in_channels=config.embed_dim,      # 输入通道数 = 词向量维度
            out_channels=config.num_filters,   # 卷积核数量（自定义超参数）
            kernel_size=3,                     # 3-gram卷积窗口
            padding=1                         # 保持序列长度不变
        )
        self.relu = nn.ReLU()

        # LSTM输入维度改为卷积后的通道数
        self.lstm = nn.LSTM(
            input_size=config.num_filters,     # 修改输入尺寸为CNN输出通道数
            hidden_size=config.hidden_size,
            num_layers=config.num_layers,
            bidirectional=True,
            batch_first=True,
            dropout=config.dropout if config.num_layers > 1 else 0
        )
        self.fc = nn.Linear(config.hidden_size * 2, config.num_classes)
        self.dropout = nn.Dropout(config.dropout)

    def forward(self, x):
        # Embedding层
        embeds = self.embedding(x)  # 输出形状: (batch, seq_len, embed_dim)

        # CNN处理
        # 调整维度为Conv1d需要的 (batch, embed_dim, seq_len)
        conv_in = embeds.permute(0, 2, 1)
        conv_out = self.conv(conv_in)          # 输出形状: (batch, num_filters, seq_len)
        conv_out = self.relu(conv_out)

        # 恢复维度为LSTM需要的 (batch, seq_len, num_filters)
        lstm_in = conv_out.permute(0, 2, 1)

        # LSTM处理
        _, (h_n, _) = self.lstm(lstm_in)  # 获取最终隐藏状态

        # 拼接双向结果
        h_n_combined = torch.cat((h_n[-2], h_n[-1]), dim=1)
        out = self.dropout(h_n_combined)
        return self.fc(out)

def setup_logging(output_dir):
    logging.basicConfig(
        filename=f'{output_dir}/training.log',
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    logging.getLogger('').addHandler(console)

def save_checkpoint(model, optimizer, epoch, metrics, output_dir, is_best=False):
    os.makedirs(f'{output_dir}/checkpoints', exist_ok=True)

    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
        'config': vars(config)
    }

    # 保存最新模型
    torch.save(checkpoint, f'{output_dir}/checkpoints/last_model.pt')

    # 保存最佳模型
    if is_best:
        torch.save(checkpoint, f'{output_dir}/checkpoints/best_model.pt')
        logging.info(f"Saved best model at epoch {epoch} (val_acc: {metrics['val_acc']:.4f})")

def evaluate(model, dataloader, criterion):
    model.eval()
    total_loss = 0
    all_preds, all_labels, all_probs = [], [], []

    with torch.no_grad():
        for inputs, labels in dataloader:
            labels = labels.squeeze() if labels.dim() > 1 else labels
            inputs, labels = inputs.to(config.device), labels.to(config.device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            # 获取预测概率（确保是二维数组）
            probs = F.softmax(outputs, dim=1).cpu().numpy()
            preds = torch.argmax(outputs, dim=1).cpu().numpy()

            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())
            # 确保正确收集正类的概率
            if probs.ndim == 2 and probs.shape[1] == 2:  # 二分类情况
                all_probs.extend(probs[:, 1])  # 只取正类的概率
            else:
                all_probs.extend(probs)  # 多分类或其他情况

    avg_loss = total_loss / len(dataloader)
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro')

    # 计算ROC AUC（确保标签是二分类且平衡）
    roc_auc = None
    if len(np.unique(all_labels)) == 2:  # 确保是二分类问题
        try:
            roc_auc = roc_auc_score(all_labels, all_probs)
        except ValueError as e:
            logging.warning(f"无法计算ROC AUC: {str(e)}")
            roc_auc = float('nan')

    report = classification_report(all_labels, all_preds, target_names=['0', '1'], zero_division=0)
    cm = confusion_matrix(all_labels, all_preds)

    return {
        'loss': avg_loss,
        'accuracy': accuracy,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'report': report,
        'y_true': all_labels,
        'y_pred': all_preds,
        'y_probs': all_probs,
        'confusion_matrix': cm
    }

def plot_metrics(train_loss, val_loss, train_acc, val_acc, output_dir):
    # 绘制损失函数和正确率曲线
    plt.figure(figsize=(12, 5))

    # Loss曲线
    plt.subplot(1, 2, 1)
    plt.plot(train_loss, label='Train')
    plt.plot(val_loss, label='Validation')
    plt.title('Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # Accuracy曲线
    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='Train')
    plt.plot(val_acc, label='Validation')
    plt.title('Accuracy Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()

    plt.tight_layout()
    plt.savefig(f'{output_dir}/figures/training_metrics.png')
    plt.close()

def plot_confusion_matrix(results, output_dir):
    # 绘制混淆矩阵
    cm = results['confusion_matrix']
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Negative', 'Positive'],
                yticklabels=['Negative', 'Positive'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.savefig(f'{output_dir}/figures/confusion_matrix.png')
    plt.close()

def plot_roc_curve(y_true, y_probs, output_dir):
    # 绘制ROC曲线
    fpr, tpr, _ = roc_curve(y_true, y_probs)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (areas = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curve')
    plt.legend(loc="lower right")
    plt.savefig(f'{output_dir}/figures/roc_curve.png')
    plt.close()

# 新增模型工厂函数
def create_model(model_type, embedding_pretrained):
    if model_type == "LSTM":
        return LSTM(embedding_pretrained).to(config.device)
    elif model_type == "AttentionLSTM":
        return AttentionLSTM(embedding_pretrained).to(config.device)
    elif model_type == "CNN_LSTM":
        return CNN_LSTM(embedding_pretrained).to(config.device)
    else:
        raise ValueError("Unknown model type")

def prepare_data():
    try:
        # 加载词表
        vocab = pkl.load(open(config.vocab_path, 'rb'))

        # 自定义分词器
        def tokenizer(text):
            text = re.sub(r'[^\w\s]', '', str(text))
            return list(text)  # 字级别分词

        # 加载数据
        df = pd.read_csv(config.data_path)
        comments = df['comment'].values
        labels = df['label'].values

        # 划分数据集
        train_comments, temp_comments, train_labels, temp_labels = train_test_split(
            comments, labels, test_size=0.4, random_state=42)
        val_comments, test_comments, val_labels, test_labels = train_test_split(
            temp_comments, temp_labels, test_size=0.5, random_state=42)

        # 创建数据集
        train_dataset = TextDataset(train_comments, train_labels, vocab, tokenizer, config.pad_size)
        val_dataset = TextDataset(val_comments, val_labels, vocab, tokenizer, config.pad_size)
        test_dataset = TextDataset(test_comments, test_labels, vocab, tokenizer, config.pad_size)

        # 创建DataLoader
        dataloaders = {
            'train': DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True),
            'val': DataLoader(val_dataset, batch_size=config.batch_size),
            'test': DataLoader(test_dataset, batch_size=config.batch_size)
        }

        return dataloaders, vocab

    except Exception as e:
        logging.error(f"数据准备错误: {str(e)}")
        raise

def train_all_models():
    model_types = ["LSTM", "AttentionLSTM", "CNN_LSTM"]
    all_metrics = {}

    for model_type in model_types:
        setup_environment()
        config = Config(model_type)  # 为每个模型创建独立配置
        setup_logging(config.output_dir)
        logging.info(f"开始训练模型: {model_type}")

        try:
            start_time = time.time()
            dataloaders, vocab = prepare_data()
            embedding_pretrained = torch.tensor(np.load(config.embedding_path)["embeddings"].astype('float32'))

            model = create_model(model_type, embedding_pretrained)
            optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5, min_lr=config.min_lr)
            criterion = nn.CrossEntropyLoss()

            best_acc = 0
            no_improve = 0
            train_losses, train_accs = [], []
            val_losses, val_accs = [], []

            # 训练循环
            for epoch in range(config.num_epochs):
                epoch_start = time.time()
                model.train()
                running_loss, correct, total = 0, 0, 0

                pbar = tqdm(dataloaders['train'], desc=f"Epoch {epoch+1}/{config.num_epochs}")
                for inputs, labels in pbar:
                    labels = labels.squeeze() if labels.dim() > 1 else labels
                    inputs, labels = inputs.to(config.device), labels.to(config.device)

                    optimizer.zero_grad()
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    preds = torch.argmax(outputs, dim=1)
                    correct += (preds == labels).sum().item()
                    total += labels.size(0)

                    pbar.set_postfix({
                        'loss': running_loss/(pbar.n+1),
                        'acc': 100*correct/total
                    })

                # 计算epoch指标
                train_loss = running_loss / len(dataloaders['train'])
                train_acc = correct / total
                train_losses.append(train_loss)
                train_accs.append(train_acc)

                # 验证评估
                val_results = evaluate(model, dataloaders['val'], criterion)
                val_losses.append(val_results['loss'])
                val_accs.append(val_results['accuracy'])

                # 学习率调整
                scheduler.step(val_results['accuracy'])

                # 保存检查点
                is_best = val_results['accuracy'] > best_acc
                if is_best:
                    best_acc = val_results['accuracy']
                    no_improve = 0
                else:
                    no_improve += 1

                save_checkpoint(
                    model, optimizer, epoch,
                    {'train_acc': train_acc, 'val_acc': val_results['accuracy']},
                    config.output_dir,
                    is_best=is_best
                )

                # 早停检查
                if no_improve >= config.patience:
                    logging.info(f"Early stopping at epoch {epoch+1}!")
                    break

                # 日志记录
                epoch_time = time.time() - epoch_start
                logging.info(f"\nEpoch {epoch+1} Summary:")
                logging.info(f"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}")
                logging.info(f"Val Loss: {val_results['loss']:.4f} | Acc: {val_results['accuracy']:.2%}")
                logging.info(f"F1 Score: {val_results['f1_score']:.4f} | AUC: {val_results['roc_auc']:.4f}")
                logging.info(f"Time: {epoch_time:.2f}s")
                logging.info(f"Classification Report:\n{val_results['report']}")


            # 训练结束评估
            logging.info("\n加载最佳模型进行测试...")
            checkpoint = torch.load(f"{config.output_dir}/checkpoints/best_model.pt")
            model.load_state_dict(checkpoint['model_state_dict'])
            test_results = evaluate(model, dataloaders['test'], criterion)

            # 计算训练耗时
            training_time = time.time() - start_time
            mins = int(training_time // 60)
            secs = int(training_time % 60)


            # 保存测试结果
            # 保存指标
            all_metrics[model_type] = {
                'train_loss': train_losses,
                'val_loss': val_losses,
                'train_acc': train_accs,
                'val_acc': val_accs,
                'test_results': test_results,
                'training_time': training_time
            }

            # 保存混淆矩阵
            np.save(f"{config.output_dir}/confusion_matrix.npy", test_results['confusion_matrix'])

        except Exception as e:
            logging.error(f"{model_type}训练失败: {str(e)}")


            # 损失曲线
            plt.subplot(2, 1, 1)
            for i, (name, metrics) in enumerate(all_metrics.items()):
                plt.plot(metrics['train_loss'], linestyle=line_styles[i], color=colors[i], label=f'{name} Train')
                plt.plot(metrics['val_loss'], linestyle=line_styles[i], color=colors[i], alpha=0.5, label=f'{name} Val')
            plt.title('Loss Comparison')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.legend()

            # 准确率曲线
            plt.subplot(2, 1, 2)
            for i, (name, metrics) in enumerate(all_metrics.items()):
                plt.plot(metrics['train_acc'], linestyle=line_styles[i], color=colors[i], label=f'{name} Train')
                plt.plot(metrics['val_acc'], linestyle=line_styles[i], color=colors[i], alpha=0.5, label=f'{name} Val')
            plt.title('Accuracy Comparison')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.legend()

            plt.tight_layout()
            plt.savefig('drive/MyDrive/LSTM/outputs/model_comparison.png')
            plt.close()

            # 输出结果
            print("=== 模型对比结果 ===")
            for name, metrics in all_metrics.items():
                print(f"\n模型: {name}")
                print(f"训练时间: {metrics['training_time']:.1f}秒")
                print(f"测试准确率: {metrics['test_results']['accuracy']:.4f}")
                print(f"混淆矩阵:\n{metrics['test_results']['confusion_matrix']}")

if __name__ == "__main__":
    train_all_models()

def prepare_data():
    try:
        # 加载词表
        vocab = pkl.load(open(config.vocab_path, 'rb'))

        # 自定义分词器
        def tokenizer(text):
            text = re.sub(r'[^\w\s]', '', str(text))
            return list(text)  # 字级别分词

        # 加载数据
        df = pd.read_csv(config.data_path)
        comments = df['comment'].values
        labels = df['label'].values

        # 划分数据集
        train_comments, temp_comments, train_labels, temp_labels = train_test_split(
            comments, labels, test_size=0.4, random_state=42)
        val_comments, test_comments, val_labels, test_labels = train_test_split(
            temp_comments, temp_labels, test_size=0.5, random_state=42)

        # 创建数据集
        train_dataset = TextDataset(train_comments, train_labels, vocab, tokenizer, config.pad_size)
        val_dataset = TextDataset(val_comments, val_labels, vocab, tokenizer, config.pad_size)
        test_dataset = TextDataset(test_comments, test_labels, vocab, tokenizer, config.pad_size)

        # 创建DataLoader
        dataloaders = {
            'train': DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True),
            'val': DataLoader(val_dataset, batch_size=config.batch_size),
            'test': DataLoader(test_dataset, batch_size=config.batch_size)
        }

        return dataloaders, vocab

    except Exception as e:
        logging.error(f"数据准备错误: {str(e)}")
        raise

# 修改后的训练函数，同时训练三种模型并比较结果
def train_and_compare_models():
    setup_environment()
    setup_logging(config.output_dir)
    logging.info(f"训练参数设置: {vars(config)}")

    start_time = time.time()

    try:
        # 准备数据
        dataloaders, vocab = prepare_data()
        embedding_pretrained = torch.tensor(np.load(config.embedding_path)["embeddings"].astype('float32'))

        # 初始化三种模型
        models = {
            'LSTM': LSTM(embedding_pretrained).to(config.device),
            'AttentionLSTM': AttentionLSTM(embedding_pretrained).to(config.device),
            'CNN_LSTM': CNN_LSTM(embedding_pretrained).to(config.device)
        }

        # 存储各模型的训练指标
        model_metrics = {
            'train_loss': {name: [] for name in models},
            'val_loss': {name: [] for name in models},
            'train_acc': {name: [] for name in models},
            'val_acc': {name: [] for name in models}
        }

        # 训练每种模型
        for model_name, model in models.items():
            logging.info(f"\n=== 开始训练 {model_name} 模型 ===")

            optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-3)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode='max', patience=2, factor=0.5, min_lr=config.min_lr)
            criterion = nn.CrossEntropyLoss()

            best_acc = 0
            no_improve = 0

            for epoch in range(config.num_epochs):
                epoch_start = time.time()
                model.train()
                running_loss, correct, total = 0, 0, 0

                pbar = tqdm(dataloaders['train'], desc=f"{model_name} - Epoch {epoch+1}/{config.num_epochs}")
                for inputs, labels in pbar:
                    labels = labels.squeeze() if labels.dim() > 1 else labels
                    inputs, labels = inputs.to(config.device), labels.to(config.device)

                    optimizer.zero_grad()
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    preds = torch.argmax(outputs, dim=1)
                    correct += (preds == labels).sum().item()
                    total += labels.size(0)

                    pbar.set_postfix({
                        'loss': running_loss/(pbar.n+1),
                        'acc': 100*correct/total
                    })

                # 记录训练指标
                train_loss = running_loss / len(dataloaders['train'])
                train_acc = 100 * correct / total
                model_metrics['train_loss'][model_name].append(train_loss)
                model_metrics['train_acc'][model_name].append(train_acc)

                # 验证评估
                val_results = evaluate(model, dataloaders['val'], criterion)
                model_metrics['val_loss'][model_name].append(val_results['loss'])
                model_metrics['val_acc'][model_name].append(val_results['accuracy']*100)

                # 学习率调整
                scheduler.step(val_results['accuracy'])

                # 早停检查
                if val_results['accuracy'] > best_acc:
                    best_acc = val_results['accuracy']
                    no_improve = 0
                else:
                    no_improve += 1

                if no_improve >= config.patience:
                    logging.info(f"{model_name} 早停在 epoch {epoch+1}!")
                    break

                # 日志记录
                epoch_time = time.time() - epoch_start
                logging.info(f"\n{model_name} Epoch {epoch+1} 结果:")
                logging.info(f"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%")
                logging.info(f"Val Loss: {val_results['loss']:.4f} | Acc: {val_results['accuracy']:.2f}%")
                logging.info(f"Time: {epoch_time:.2f}s")

        # 定义灰度色调和线条样式
        model_styles = {
          'LSTM': {
          'train_color': '0.1',  # 深灰
          'val_color': '0.1',
          'train_linestyle': '--',
          'val_linestyle': '-',
          'train_marker': '',
          'val_marker': 'o',
          'markersize': 4
          },
        'AttentionLSTM': {
          'train_color': '0.4',  # 中灰
          'val_color': '0.4',
          'train_linestyle': '--',
          'val_linestyle': '-',
          'train_marker': '',
          'val_marker': 's',
          'markersize': 4
          },
        'CNN_LSTM': {
          'train_color': '0.7',  # 浅灰
          'val_color': '0.7',
          'train_linestyle': '--',
          'val_linestyle': '-',
          'train_marker': '',
          'val_marker': '^',
          'markersize': 4
          }
        }

        # 绘制比较图表
        plt.figure(figsize=(14, 6))

        # 损失曲线比较
        plt.subplot(1, 2, 1)
        for model_name in models:
            style = model_styles[model_name]
            # 训练损失
            plt.plot(model_metrics['train_loss'][model_name],
                    color=style['train_color'],
                    linestyle=style['train_linestyle'],
                    marker=style['train_marker'],
                    label=f'{model_name} Train')
            # 验证损失
            plt.plot(model_metrics['val_loss'][model_name],
                    color=style['val_color'],
                    linestyle=style['val_linestyle'],
                    marker=style['val_marker'],
                    markersize=style['markersize'],
                    label=f'{model_name} Val')
        plt.title('Loss Curve Comparison (Grayscale Optimized)')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True, linestyle=':', alpha=0.6)  # 添加浅色网格线增强可读性
        plt.legend()

        # 准确率曲线比较
        plt.subplot(1, 2, 2)
        for model_name in models:
            style = model_styles[model_name]
            # 训练准确率
            plt.plot(model_metrics['train_acc'][model_name],
                    color=style['train_color'],
                    linestyle=style['train_linestyle'],
                    marker=style['train_marker'],
                    label=f'{model_name} Train')
            # 验证准确率
            plt.plot(model_metrics['val_acc'][model_name],
                    color=style['val_color'],
                    linestyle=style['val_linestyle'],
                    marker=style['val_marker'],
                    markersize=style['markersize'],
                    label=f'{model_name} Val')
        plt.title('Accuracy Curve Comparison (Grayscale Optimized)')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.grid(True, linestyle=':', alpha=0.6)  # 添加浅色网格线增强可读性
        plt.legend()

        plt.tight_layout()
        plt.savefig(f'{config.output_dir}/figures/model_comparison_grayscale.png', dpi=300)
        plt.close()

        # 评估每种模型的测试性能
        test_results = {}
        for model_name, model in models.items():
            checkpoint_path = f"{config.output_dir}/checkpoints/{model_name}_best_model.pt"
            if os.path.exists(checkpoint_path):
                checkpoint = torch.load(checkpoint_path)
                model.load_state_dict(checkpoint['model_state_dict'])
                test_results[model_name] = evaluate(model, dataloaders['test'], criterion)
                logging.info(f"\n{model_name} 测试结果:")
                logging.info(f"Test Accuracy: {test_results[model_name]['accuracy']:.2%}")
                logging.info(f"F1 Score: {test_results[model_name]['f1_score']:.4f}")
                logging.info(f"AUC-ROC: {test_results[model_name]['roc_auc']:.4f}")

        # 计算总训练耗时
        training_time = time.time() - start_time
        mins = int(training_time // 60)
        secs = int(training_time % 60)
        logging.info(f"\n总训练耗时: {mins}分{secs}秒")

    except Exception as e:
        logging.error(f"训练过程中发生错误: {str(e)}")
        raise

if __name__ == "__main__":
    train_and_compare_models()









